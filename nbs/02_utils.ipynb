{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\r\n",
    "\r\n",
    "> This module offers useful utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\r",
    "from nbverbose.showdoc import **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import ast\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "# from fastcore.xtras import globtastic\n",
    "\n",
    "# pydicom related imports\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "# kagglerecipes imports\n",
    "from kagglerecipes.data import TINY_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Utils\n",
    "Will be removed on next fastcore release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "'''\n",
    "TEMPORARY UTILS ADDED HERE UNTIL THE NEXT fastcore RELEASE\n",
    "'''\n",
    "from fastcore.imports import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.basics import *\n",
    "from functools import wraps\n",
    "\n",
    "from typing import Iterable,Generator,Sequence,Iterator,List,Set,Dict,Union,Optional\n",
    "\n",
    "import mimetypes,pickle,random,json,subprocess,shlex,bz2,gzip,zipfile,tarfile\n",
    "import imghdr,struct,distutils.util,tempfile,time,string,collections,shutil\n",
    "from copy import copy\n",
    "from contextlib import contextmanager,ExitStack\n",
    "from pdb import set_trace\n",
    "from datetime import datetime, timezone\n",
    "from timeit import default_timer\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "def globtastic(\n",
    "    path:Union[Path,str], # path to start searching\n",
    "    recursive:bool=True, # search subfolders\n",
    "    symlinks:bool=True, # follow symlinks?\n",
    "    file_glob:str=None, # Only include files matching glob\n",
    "    file_re:str=None, # Only include files matching regex\n",
    "    folder_re:str=None, # Only enter folders matching regex\n",
    "    skip_file_glob:str=None, # Skip files matching glob\n",
    "    skip_file_re:str=None, # Skip files matching regex\n",
    "    skip_folder_re:str=None # Skip folders matching regex\n",
    ")->L: # Paths to matched files\n",
    "    \"A more powerful `glob`, including regex matches, symlink handling, and skip parameters\"\n",
    "    path = Path(path)\n",
    "    if path.is_file(): return L([path])\n",
    "    if not recursive: skip_folder_re='.'\n",
    "    file_re,folder_re = compile_re(file_re),compile_re(folder_re)\n",
    "    skip_file_re,skip_folder_re = compile_re(skip_file_re),compile_re(skip_folder_re)\n",
    "    def _keep_file(root, name):\n",
    "        return (not file_glob or fnmatch(name, file_glob)) and (\n",
    "                not file_re or file_re.search(name)) and (\n",
    "                not skip_file_glob or not fnmatch(name, skip_file_glob)) and (\n",
    "                not skip_file_re or not skip_file_re.search(name))\n",
    "    def _keep_folder(root, name):\n",
    "        return (not folder_re or folder_re.search(name)) and (\n",
    "            not skip_folder_re or not skip_folder_re.search(name))\n",
    "    return L(walk(path, symlinks=symlinks, keep_file=_keep_file, keep_folder=_keep_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compile_re(pat):\n",
    "    \"Compile `pat` if it's not None\"\n",
    "    return None if pat is None else re.compile(pat)\n",
    "\n",
    "def walk(\n",
    "    path:(Path,str), # path to start searching\n",
    "    symlinks:bool=True, # follow symlinks?\n",
    "    keep_file:callable=noop, # function that returns True for wanted files\n",
    "    keep_folder:callable=noop, # function that returns True for folders to enter\n",
    "    func:callable=os.path.join # function to apply to each matched file\n",
    "): # Generator of `func` applied to matched files\n",
    "    \"Generator version of `os.walk`, using functions to filter files and folders\"\n",
    "    for root,dirs,files in os.walk(path, followlinks=symlinks):\n",
    "        yield from (func(root, name) for name in files if keep_file(root,name))\n",
    "        for name in copy(dirs):\n",
    "            if not keep_folder(root,name): dirs.remove(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names from Kaggle Brain Tumor DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "kaggle_braintumor_meta_cols = ['SpecificCharacterSet','ImageType','SOPClassUID',\r\n",
    "             'SOPInstanceUID','AccessionNumber','Modality', 'SeriesDescription', \r\n",
    "             'PatientID', 'MRAcquisitionType', 'SliceThickness', \r\n",
    "             'EchoTime', 'NumberOfAverages', 'ImagingFrequency', 'ImagedNucleus', \r\n",
    "             'MagneticFieldStrength', 'SpacingBetweenSlices', \r\n",
    "             'EchoTrainLength', 'PercentSampling', 'PercentPhaseFieldOfView',\r\n",
    "             'PixelBandwidth', 'TriggerWindow', 'ReconstructionDiameter', 'AcquisitionMatrix',\r\n",
    "             'FlipAngle', 'SAR', 'PatientPosition',\r\n",
    "             'StudyInstanceUID', 'SeriesInstanceUID', 'SeriesNumber', 'InstanceNumber',\r\n",
    "             'ImagePositionPatient', 'ImageOrientationPatient', 'Laterality',\r\n",
    "             'PositionReferenceIndicator', 'SliceLocation', 'InStackPositionNumber',\r\n",
    "             'SamplesPerPixel', 'PhotometricInterpretation', 'Rows', 'Columns', 'PixelSpacing',\r\n",
    "             'BitsAllocated', 'BitsStored', 'HighBit', 'PixelRepresentation', 'WindowCenter',\r\n",
    "             'WindowWidth', 'RescaleIntercept', 'RescaleSlope', 'RescaleType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the metadata of a single dicom file as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dicom_metadata(\n",
    "    path_to_dicom_file:str, # path to the dicom file\n",
    "    meta_cols:list # list of metadata columns to extract from the dicom file\n",
    "):\n",
    "    \"Returns the metadata of a single dicom file as a dictionary.\"\n",
    "    \n",
    "    dicom_object = pydicom.dcmread(path_to_dicom_file)\n",
    "\n",
    "    col_dict_train = dict()\n",
    "    for col in meta_cols: \n",
    "        try:\n",
    "            col_dict_train[col] = str(getattr(dicom_object, col))\n",
    "        except AttributeError:\n",
    "            col_dict_train[col] = \"NaN\"\n",
    "    \n",
    "    return col_dict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = globtastic(TINY_DATA_PATH, file_glob='*.*dcm*')[0]\r\n",
    "dicom_metadata = get_dicom_metadata(sample_file, kaggle_braintumor_meta_cols)\r\n",
    "assert type(dicom_metadata) == dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve metadata for each BraTS21ID and return as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the correct patient id of a dicom file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_patient_id(\n",
    "    patient_id:int # patient id of the dicom file\n",
    "):\n",
    "    \"Returns a patient id as a string, formatted as the Kaggle Brain Tumor competition data expects e.g 20 will return 00020\"\n",
    "\n",
    "    if patient_id < 10:\n",
    "        return '0000'+str(patient_id)\n",
    "    elif patient_id >= 10 and patient_id < 100:\n",
    "        return '000'+str(patient_id)\n",
    "    elif patient_id >= 100 and patient_id < 1000:\n",
    "        return '00'+str(patient_id)\n",
    "    else:\n",
    "        return '0'+str(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_patient_id(1) == '00001'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path to patient folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_patient_BraTS21ID_path(\n",
    "    row,  # Row from a DataFrame\n",
    "    path:str # Path to patient folders, e.g. could be \"train\" or \"test\"\n",
    "):\n",
    "    \"Construct the path to a patient id folder from a DataFrame row\"\n",
    "    \n",
    "    patient_id = get_patient_id(int(row.BraTS21ID))\n",
    "    return f'{path}/{patient_id}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = TINY_DATA_PATH/'train'\r\n",
    "train_df = pd.read_csv(TINY_DATA_PATH/'train_labels.csv')\r\n",
    "# This assertion fails in a Windows system due to path with \\\\\r\n",
    "# assert get_patient_BraTS21ID_path(train_df.iloc[0], TRAIN_PATH) == 'data\\\\tiny\\\\train/00000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_all_dicom_metadata(\n",
    "    df,  # DataFrame with patient folder ids and BraTS21IDs\n",
    "    meta_cols:list,  # List of metadata columns to extract\n",
    "    scan_types:list=['FLAIR', 'T1w', 'T1wCE', 'T2w']  # List of strings of mdedical scan types, default: ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "):\n",
    "    \"Reads dicom files and returns a dataframe of all dicom metadata, for each BraTS21ID id and each scan type folder.\"\n",
    "    \n",
    "    meta_cols_dict = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        path = Path(row.path) \n",
    "        for scan_type in scan_types:\n",
    "            dcm_file_paths = globtastic(path / scan_type, file_glob='*.*dcm*')\n",
    "            for pth in dcm_file_paths:\n",
    "                dicom_metadata = get_dicom_metadata(pth, meta_cols)\n",
    "                dicom_metadata['scan_type'] = scan_type\n",
    "                dicom_metadata['id'] = row.BraTS21ID\n",
    "                meta_cols_dict.append(dicom_metadata)\n",
    "            \n",
    "    return pd.DataFrame(meta_cols_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patient_path = TRAIN_PATH / os.listdir(TRAIN_PATH)[0]\r\n",
    "\r\n",
    "# construct path based on csv and TRAIN_PATH\r\n",
    "train_df['path'] = train_df.apply(lambda row: get_patient_BraTS21ID_path(row, TRAIN_PATH), axis=1)\r\n",
    "\r\n",
    "folder_exists = train_df['path'] == str(data_patient_path)+'/'\r\n",
    "train_df = train_df[folder_exists]\r\n",
    "\r\n",
    "# Again failing because of windows path issue\r\n",
    "# assert len(train_df) >= 1\r\n",
    "# assert len(get_all_dicom_metadata(train_df, kaggle_braintumor_meta_cols)) == 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the MRI's plane from the dicom data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_plane(\n",
    "    data:dict  # Dictionary of dicom metadata\n",
    "):\n",
    "    \"Returns the MRI's plane from the dicom data.\"\n",
    "\n",
    "    x1,y1,_,x2,y2,_ = [round(j) for j in ast.literal_eval(data.ImageOrientationPatient)]\n",
    "    cords = [x1,y1,x2,y2]\n",
    "\n",
    "    if cords == [1,0,0,0]:\n",
    "        return 'coronal'\n",
    "    if cords == [1,0,0,1]:\n",
    "        return 'axial'\n",
    "    if cords == [0,1,0,0]:\n",
    "        return 'sagittal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.ipynb.\n",
      "Converted 01_preprocess.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_wandb_utils.ipynb.\n",
      "Converted 04_wandb_viz.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\r\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
